.. _mnist:

(Local) Robustness of MNIST dataset
***********************************

CAISAR provides a convenient way for verifying (local) robustness properties of
neural networks working on datasets with values in :math:`[0, 1]`, for
classification problems only. For the moment, CAISAR supports datasets in a
specific ``CSV`` format only, where each ``CSV`` lines is interpreted as
providing the classification label in the first column, and the dataset element
features in the remaining columns.

We recall that a neural network is deemed robust on a dataset element whenever
it classify with a same label all other elements being at an
:math:`l_\infty`-distance of at most :math:`\epsilon \geq 0` from it. More in
general, a neural network is deemed (locally) robust on a dataset whenever the
former property is valid on all the dataset elements. The CAISAR standard
library specifies such a property in terms of the predicate ``robust``, which
CAISAR implements as a builtin.

In the following, we will describe how to use CAISAR for verifying a neural
network robust on (a fragment of) the MNIST dataset.

Use case presentation
=====================

MNIST is a dataset of handwritten digits normalized and centered to fit into
grayscale images of :math:`28 \times 28` pixels, along with the classification
labels [LiDeng2012]_. Although it is mostly irrelevant as dataset for
benchmarking machine learning models for computer vision tasks, MNIST is still
valuable for assessing robustness properties by means of formal method tools.

CAISAR provides in `mnist_test.csv
<https://git.frama-c.com/pub/caisar/-/blob/master/examples/mnist/csv/mnist_test.csv>`_
a fragment (:math:`100` images) of the MNIST dataset under the
``examples/mnist/csv`` folder. Each line in this file represents an MNIST image:
in particular, the first column represents the classification label, and the
remaining :math:`784` columns represent the greyscale value of the respective
pixels, rescaled into :math:`[0, 1]`.

Properties
----------

Generally speaking, the property we are interested in verifying is the local
robustness of a machine learning model on the elements of a set. That is, the
model classifies all elements of a set being at an :math:`l_\infty`-distance of
at most :math:`\epsilon \geq 0` with a same label. A general formulation of this
latter states that, given a classifier :math:`C`, a set :math:`X`, and some
perturbation :math:`\epsilon \geq 0`, it must hold that :math:`\forall x,x'
\in X. \ \lVert x - x' \rVert_\infty \leq \epsilon \Rightarrow C(x) = C(x')`.

Since we actually deal with a *dataset* of finite elements for which we also
know the expected labels, we will instead verify a slightly different property:
given a classifier :math:`C`, an element :math:`x \in X` such that :math:`C(x) =
y`, and some perturbation :math:`\epsilon \geq 0`, it must hold that
:math:`\forall x'. \ \lVert x - x' \rVert_\infty \leq \epsilon \Rightarrow C(x)
= y = C(x')`. Obviously, such a property must be verified for all elements of a
dataset.

Modelling the problem using WhyML
---------------------------------

As described for the example on :ref:`acas_xu`, we first need to write a
specification file containing a WhyML theory to describe the verification
problem. In principle, we need to formalize the local robustness property as
well as the notions of classifier and dataset.

The CAISAR standard library `caisar.mlw
<https://git.frama-c.com/pub/caisar/-/blob/master/stdlib/caisar.mlw>`_ provides
some utilities for dealing with verification problems about classification
datasets. Of particular interest for us is the ``robust`` predicate, defined in
the theory ``DatasetClassificationProps`` as follows:

.. code-block:: whyml

  predicate robust (m: model) (d: dataset) (eps: t) =
    forall i: int. 0 <= i < d.data.length -> robust_at m d.data[i] eps

Note that the predicate is defined over a ``model``, a ``dataset`` and a
floating-point value ``eps``. The latter determines the perturbation
:math:`\epsilon`. The other two are custom WhyML types that respectively
formalize the notions of classifier and dataset in CAISAR. These types are
both defined in the ``DatasetClassification`` theory.

Moreover, it is defined in terms of the predicate ``robust_at`` that formalizes
the local robustness property:

.. code-block:: whyml

  predicate robust_at (m: model) (d: record) (eps: t) =
    forall x': features.
      let (x, _) = d in
      linfty_distance x x' eps ->
      predict m x = predict m x'

Note that a ``record`` is a dataset element given as a pair of *features* and
(classification) *label*. Morever, ``linfty_distance`` is a predicate that
describes how two arrays of floating-point values (*i.e.* ``features``) are
considered close up-to a pertubation ``eps``, while ``predict`` is a function
that formalizes the execution of a model on some features to obtain the
corresponding classification label.

In order to use the ``robust`` predicate in our WhyML specification, we need
values of types ``model`` and ``dataset``. For the former, CAISAR makes
available the constant ``model`` upon interpreting the ``AsArray`` sub-theory
that is built by the extension of the Why3 standard library for recognizing
neural network ONNX and NNet formats. For the latter, the CAISAR standard
library provides the constant ``dataset`` in ``DatasetClassification`` that will
be interpreted as the actual dataset the user needs to provide via the
command-line interface when launching a CAISAR verification.

Assuming we have a neural network named ``MNIST_256_2.onnx`` for MNIST
classification, the final WhyML file for specifying its local robustness on a
dataset, with each element's feature pertubed by :math:`1 \%`, looks like this:

.. code-block:: whyml

   theory MNIST
     use MNIST_256_2.AsArray
     use ieee_float.Float64
     use caisar.DatasetClassification
     use caisar.DatasetClassificationProps

     goal robustness:
      robust model dataset (0.0100000000000000002081668171172168513294309377670288085937500000:t)
   end

This file is available, as is, under the ``/examples/mnist/`` folder as
`property.why
<https://git.frama-c.com/pub/caisar/-/blob/master/examples/mnist/property.why>`_.
The corresponding neural network in ONNX format is available under the
``/examples/mnist/nets/`` folder as `MNIST_256_2.onnx
<https://git.frama-c.com/pub/caisar/-/blob/master/examples/mnist/nets/MNIST_256_2.onnx>`_.

Verifying the property with CAISAR
----------------------------------

Now we may verify whether the previous robustness specification holds on the
MNIST fragment ``mnist_test.csv`` by means of the nnenum prover. This can be
done via CAISAR as follows:

.. code-block:: console

   $ caisar verify --prover nnenum -L examples/mnist/nets --format whyml --dataset=examples/mnist/csv/mnist_test.csv examples/mnist/property.why
   [caisar] Goal robustness: Invalid

The result tells us that there exists at least one image in ``mnist_test.csv``
for which nnenum is sure that the model ``MNIST_256_2.onnx`` is not robust with
respect to :math:`1 \%` perturbation. At the moment, CAISAR is not able to tell
which are the images in the dataset that cause such result.

.. [LiDeng2012] Li Deng, *The MNIST Database of Handwritten Digit Images for
               Machine Learning Research*, IEEE Signal Process. Mag., 2012, pp.
               141-142, doi: 10.1109/MSP.2012.2211477
