
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4.1. Functional properties of ACAS-Xu &#8212; CAISAR 0.2 documentation</title>
    <link rel="stylesheet" type="text/css" href="static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="static/graphviz.css" />
    <script data-url_root="./" id="documentation_options" src="static/documentation_options.js"></script>
    <script src="static/jquery.js"></script>
    <script src="static/underscore.js"></script>
    <script src="static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4.2. (Local) Robustness of MNIST dataset" href="mnist.html" />
    <link rel="prev" title="4. CAISAR by Examples" href="examples.html" />
   
  <link rel="stylesheet" href="static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="functional-properties-of-acas-xu">
<span id="acas-xu"></span><h1><span class="section-number">4.1. </span>Functional properties of ACAS-Xu<a class="headerlink" href="#functional-properties-of-acas-xu" title="Permalink to this headline">¶</a></h1>
<p>ACAS-Xu stands for Aircraft Collision Avoidance System. Introduced for instance
in <a class="reference internal" href="#manfredi2016" id="id1"><span>[Manfredi2016]</span></a>, it is a specification of a program which aim to output
signals for an aircraft in a situation where there is a potential for collision.
In the rest of this tutorial, we will use the flavour ACAS-Xu defined in
<a class="reference internal" href="#katz2017" id="id2"><span>[Katz2017]</span></a>, where the authors aim to verify a neural network implementing part
of the ACAS-Xu specification. Its low dimensionality and well-defined semantics
make it a <em>de facto</em> benchmark for machine learning verification.</p>
<section id="use-case-presentation">
<h2><span class="section-number">4.1.1. </span>Use case presentation<a class="headerlink" href="#use-case-presentation" title="Permalink to this headline">¶</a></h2>
<p>The system considers a 2D plane with two entities: the monitored airplane (the
“ownship”) and an incoming airplane (the “intruder”).</p>
<a class="reference internal image-reference" href="images/acas_xu.png"><img alt="A schematic with two aircraft, seen from above, displaying the relative angles of their trajectories" class="align-center" src="images/acas_xu.png" style="width: 272.5px; height: 180.5px;" /></a>
<p>In the original implementation, the system state has seven inputs:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(v_{own}\)</span>: speed of ownship</p></li>
<li><p><span class="math notranslate nohighlight">\(v_{int}\)</span>: speed of intruder</p></li>
<li><p><span class="math notranslate nohighlight">\(\rho\)</span>: distance from ownship to intruder</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span>: angle to intruder relative to ownship heading direction</p></li>
<li><p><span class="math notranslate nohighlight">\(\psi\)</span>: heading angle of intruder relative to ownship heading direction</p></li>
<li><p><span class="math notranslate nohighlight">\(\tau\)</span>: time until vertical separation</p></li>
<li><p><span class="math notranslate nohighlight">\(a_{prev}\)</span>: previous advisory</p></li>
</ul>
<p>It has five outputs, that correspond to the different direction advisories the
system can give:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(COC\)</span>: Clear Of Conflict</p></li>
<li><p><span class="math notranslate nohighlight">\(WL\)</span>: Weak Left</p></li>
<li><p><span class="math notranslate nohighlight">\(SL\)</span>: Strong Left</p></li>
<li><p><span class="math notranslate nohighlight">\(WR\)</span>: Weak Right</p></li>
<li><p><span class="math notranslate nohighlight">\(SR\)</span>: Strong Right</p></li>
</ul>
<p>In the original paper, the authors consider <span class="math notranslate nohighlight">\(45\)</span> neural networks, for
several values of <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(a_{prev}\)</span>, that operate on five inputs
only while maintaining the same number of outputs. We will consider five-inputs
networks in the remaining of this example.</p>
<section id="properties">
<h3><span class="section-number">4.1.1.1. </span>Properties<a class="headerlink" href="#properties" title="Permalink to this headline">¶</a></h3>
<p>There are several functional properties one may want to verify on this system,
for instance:</p>
<ul class="simple">
<li><p>Guarantee that the system will never output COC advisory when the intruder is
nearby,</p></li>
<li><p>Guarantee that the system will never output an advisory that may result in a
collision,</p></li>
<li><p>Guarantee that the system will not output a strong advisory where a weak
variant would be enough.</p></li>
</ul>
<p>Authors of <a class="reference internal" href="#katz2017" id="id3"><span>[Katz2017]</span></a> propose ten properties to verify. We will reproduce the
first and third properties here, and then show how to use CAISAR for verifying
whether a given neural network respects them.</p>
<p><strong>Property</strong> <span class="math notranslate nohighlight">\(\phi_1\)</span></p>
<ul>
<li><p><strong>Definition.</strong>
If the intruder is distant and is significantly slower than
the ownship, the score of a COC advisory will always be below a certain fixed
threshold.</p></li>
<li><p><strong>Input constraints:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\rho \geq 55947.691\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(v_{own} \geq 1145\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(v_{int} \leq 60\)</span>.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Desired output property:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(COC \leq 1500\)</span>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p><strong>Property</strong> <span class="math notranslate nohighlight">\(\phi_3\)</span></p>
<ul>
<li><p><strong>Definition.</strong>
If the intruder is directly ahead and is moving towards the
ownship, the score for COC will not be minimal.</p></li>
<li><p><strong>Input constraints:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(1500 \leq \rho \leq 1800\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(-0.06 \leq \theta \leq 0.06\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(\psi \geq 3.10\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(v_{own} \geq 980\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(v_{int} \geq 960\)</span>.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Desired output property:</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(COC\)</span> is not the minimal score.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="modelling-the-problem-using-whyml">
<h3><span class="section-number">4.1.1.2. </span>Modelling the problem using WhyML<a class="headerlink" href="#modelling-the-problem-using-whyml" title="Permalink to this headline">¶</a></h3>
<p>The first step for verifying anything with CAISAR is to write a specification
file that describe the problem to verify as a so-called <em>theory</em>. A theory can
be seen as a namespace inside which are defined logical terms, formulas and
verification goals. In particular, being based on the <a class="reference external" href="https://why3.lri.fr">Why3</a> platform for deductive program verification, CAISAR
supports the Why3 specification language
<a class="reference external" href="https://why3.lri.fr/doc/syntaxref.html">WhyML</a>, and inherits the Why3 standard
library of logical theories (integer, float and real arithmetic, <em>etc.</em>) and
basic programming data structures (arrays, queues, hash tables, <em>etc.</em>).</p>
<p>Additionnaly, CAISAR extends WhyML by providing several builtins
predicates and function symbols.
The full extend of those additions will be documented in a future release.
This example will use some of those undocumented extensions
to display the capabilities of CAISAR; the wording “WhyML extensions” will be used when this happens.
We believe those
extensions are simple enough so that their meaning in the
verification is transparent.</p>
<p>Let us try to model the property <span class="math notranslate nohighlight">\(\phi_1\)</span> defined earlier. We will call
our theory <code class="docutils literal notranslate"><span class="pre">ACASXU_P1</span></code>.</p>
<p>We will need to write down some numerical values. As of now, CAISAR allows
writing values using floating-point arithmetic only. Why3 defines a float type
and the relevant arithmetic operations according to the IEEE floating-point
standard in a theory, astutely called <code class="docutils literal notranslate"><span class="pre">ieee_float</span></code>. Specifically, we will
import the <code class="docutils literal notranslate"><span class="pre">Float64</span></code> sub-theory, that defines everything we need for 64-bit
precision floating-point numbers. We thus import it in our theory using the
<code class="docutils literal notranslate"><span class="pre">use</span></code> keyword.</p>
<p>Our file looks like this so far:</p>
<div class="highlight-whyml notranslate"><div class="highlight"><pre><span></span><span class="k">theory</span> <span class="n">ACASXU_P1</span>
  <span class="k">use</span> <span class="n">ieee_float</span><span class="p">.</span><span class="n">Float64</span>
<span class="k">end</span>
</pre></div>
</div>
<p>We would like to verify our property given a certain neural network. To do this,
CAISAR provide WhyML extensions to recognize and apply
neural networks in ONNX and NNet formats on vector inputs.
Given a file of such formats, CAISAR is able to provide the following:</p>
<ul class="simple">
<li><p>a logical symbol of type <code class="docutils literal notranslate"><span class="pre">nn</span></code>, built using the <code class="docutils literal notranslate"><span class="pre">read_neural_network</span></code> function, of type <code class="docutils literal notranslate"><span class="pre">string</span> <span class="pre">-&gt;</span> <span class="pre">format</span> <span class="pre">-&gt;</span> <span class="pre">nn</span></code>. The first argument is the path to the neural network file, <code class="docutils literal notranslate"><span class="pre">format</span></code> is either <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> or <code class="docutils literal notranslate"><span class="pre">NNet</span></code>, and <code class="docutils literal notranslate"><span class="pre">nn</span></code> is the type of the neural network in WhyML;</p></li>
<li><p>a function symbol that returns the output of the application of the neural network to a given input;</p></li>
<li><p>types and predicates to manipulate inputs vectors;</p></li>
</ul>
<p>The full reference for those WhyML extensions is available under the
<a class="reference external" href="https://git.frama-c.com/pub/caisar/-/blob/master/stdlib/interpretation.mlw">stdlib/interpretation.mlw</a> file. To create a logical symbol for a neural network located in “nets/onnx/ACASXU_1_1.onnx”, we can import the relevant theories in our file and use the <code class="docutils literal notranslate"><span class="pre">read_neural_network</span></code> function symbol like this:</p>
<div class="highlight-whyml notranslate"><div class="highlight"><pre><span></span><span class="k">theory</span> <span class="n">ACASXU_P1</span>
  <span class="k">use</span> <span class="n">ieee_float</span><span class="p">.</span><span class="n">Float64</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">Vector</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">NeuralNetwork</span>

  <span class="k">constant</span> <span class="n">nn_1_1</span><span class="p">:</span> <span class="n">nn</span> <span class="o">=</span> <span class="n">read_neural_network</span> <span class="s2">&quot;nets/onnx/ACASXU_1_1.onnx&quot;</span> <span class="n">ONNX</span>
<span class="k">end</span>
</pre></div>
</div>
<p>Now is the time to define our verification goal, that will call <code class="docutils literal notranslate"><span class="pre">P1_1_1</span></code> for
property <span class="math notranslate nohighlight">\(\phi_1\)</span> on neural network <span class="math notranslate nohighlight">\(N_{1,1}\)</span>.
We first model the inputs of the neural network <span class="math notranslate nohighlight">\(\rho, \theta, \psi,
v_{own}, v_{int}\)</span> respectively as the floating-points constants <span class="math notranslate nohighlight">\(x_i\)</span> for
<span class="math notranslate nohighlight">\(i \in [0..4]\)</span>. Moreover, we constrain these to the range of
floating-point values each may take. According to the original authors, values
were normalized during the training of the network, and so we adapt the values
they provide in their <a class="reference external" href="https://github.com/NeuralNetworkVerification/Marabou/tree/master/resources/properties">repository</a>. Since we will manipulate integer indexes, we require the use of the <code class="docutils literal notranslate"><span class="pre">int.Int</span></code> Why3 library. We can write that as a predicate for clarity:</p>
<div class="highlight-whyml notranslate"><div class="highlight"><pre><span></span><span class="k">theory</span> <span class="n">ACASXU_P1</span>
  <span class="k">use</span> <span class="n">ieee_float</span><span class="p">.</span><span class="n">Float64</span>
  <span class="k">use</span> <span class="n">int</span><span class="p">.</span><span class="n">Int</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">Vector</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">NeuralNetwork</span>

  <span class="k">constant</span> <span class="n">nn_1_1</span><span class="p">:</span> <span class="n">nn</span> <span class="o">=</span> <span class="n">read_neural_network</span> <span class="s2">&quot;nets/onnx/ACASXU_1_1.onnx&quot;</span> <span class="n">ONNX</span>

  <span class="k">predicate</span> <span class="n">valid_input</span> <span class="p">(</span><span class="n">i</span><span class="p">:</span> <span class="n">vector</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5999999999999999777955395074968691915273666381835937500000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">6798577687000000313588543576770462095737457275390625000000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">4500000000000000111022302462515654042363166809082031250000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">4500000000000000111022302462515654042363166809082031250000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
<p>We must then define the result of the application of <code class="docutils literal notranslate"><span class="pre">nn_1_1</span></code> on the inputs.
The built-in function <code class="docutils literal notranslate"><span class="pre">&#64;&#64;</span></code> serves this purpose. Its type, <code class="docutils literal notranslate"><span class="pre">nn</span> <span class="pre">-&gt;</span> <span class="pre">vector</span> <span class="pre">'a</span> <span class="pre">-&gt;</span> <span class="pre">vector</span> <span class="pre">'a</span></code>, describes what it does: given a neural network <code class="docutils literal notranslate"><span class="pre">nn</span></code> and an input vector <code class="docutils literal notranslate"><span class="pre">x</span></code>, return the vector that is the result of the application of <code class="docutils literal notranslate"><span class="pre">nn</span></code> on <code class="docutils literal notranslate"><span class="pre">x</span></code>.
Note that thanks to type polymorphism, <code class="docutils literal notranslate"><span class="pre">&#64;&#64;</span></code> can be used to
describe a variety of input vectors, including floating points, integers, or strings.
We can finally define the output constraint
we want to enforce on the first coordinate of the output vector that we use to
model the advisory <em>COC</em>. We use the WhyML extension
predicate <code class="docutils literal notranslate"><span class="pre">has_length</span></code> to further check that our inputs
are of valid length.</p>
<p>The final WhyML file looks like this:</p>
<div class="highlight-whyml notranslate"><div class="highlight"><pre><span></span><span class="k">theory</span> <span class="n">ACASXU_P1</span>
  <span class="k">use</span> <span class="n">ieee_float</span><span class="p">.</span><span class="n">Float64</span>
  <span class="k">use</span> <span class="n">int</span><span class="p">.</span><span class="n">Int</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">Vector</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">NeuralNetwork</span>

  <span class="k">constant</span> <span class="n">nn_1_1</span><span class="p">:</span> <span class="n">nn</span> <span class="o">=</span> <span class="n">read_neural_network</span> <span class="s2">&quot;nets/onnx/ACASXU_1_1.onnx&quot;</span> <span class="n">ONNX</span>

  <span class="k">predicate</span> <span class="n">valid_input</span> <span class="p">(</span><span class="n">i</span><span class="p">:</span> <span class="n">vector</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5999999999999999777955395074968691915273666381835937500000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">6798577687000000313588543576770462095737457275390625000000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">4500000000000000111022302462515654042363166809082031250000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">4500000000000000111022302462515654042363166809082031250000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>

  <span class="k">goal</span> <span class="n">P1_1_1</span><span class="p">:</span>
    <span class="k">forall</span> <span class="n">i</span><span class="p">:</span> <span class="n">vector</span> <span class="n">t</span><span class="p">.</span> <span class="n">has_length</span> <span class="n">i</span> <span class="mi">5</span> <span class="o">-&gt;</span> <span class="n">valid_input</span> <span class="n">i</span> <span class="o">-&gt;</span>
      <span class="p">(</span><span class="n">nn_1_1</span><span class="err">@@</span><span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">3</span><span class="p">.</span><span class="mi">9911256458999999630066213285317644476890563964843750000000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
<p>This file is available, as is, under the <code class="docutils literal notranslate"><span class="pre">/examples/acasxu/</span></code> folder as
<a class="reference external" href="https://git.frama-c.com/pub/caisar/-/blob/master/examples/acasxu/property_1.why">property_1.why</a>.
The corresponding neural network in ONNX format is available under the
<code class="docutils literal notranslate"><span class="pre">/examples/acasxu/nets/onnx/</span></code> folder as <a class="reference external" href="https://git.frama-c.com/pub/caisar/-/blob/master/examples/acasxu/nets/onnx/ACASXU_1_1.onnx">ACASXU_1_1.onnx</a>.</p>
</section>
<section id="verifying-the-property-with-caisar">
<h3><span class="section-number">4.1.1.3. </span>Verifying the property with CAISAR<a class="headerlink" href="#verifying-the-property-with-caisar" title="Permalink to this headline">¶</a></h3>
<p>Once formalized, the specified property can be assessed by using CAISAR. We will
use the <em>open-source</em> provers CAISAR supports for verifying properties of neural
networks so to take advantage of the federating approach: whenever one prover
cannot provide an answer, another may instead. In particular, we will use
<a class="reference external" href="https://github.com/NeuralNetworkVerification/Marabou">Marabou</a> and <a class="reference external" href="https://github.com/stanleybak/nnenum">nnenum</a>.</p>
<p>Assuming the prover locations are available in <code class="docutils literal notranslate"><span class="pre">PATH</span></code>, the following are the
CAISAR verification invocations using Marabou first and nnenum afterwords, for
verifying the ACAS-Xu property <span class="math notranslate nohighlight">\(\phi_1\)</span>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>caisar verify --prover Marabou -L examples/acasxu/nets/onnx --format whyml examples/acasxu/property_1.why -t 10m
<span class="go">[caisar] Goal P1_1_1: Timeout</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>caisar verify --prover nnenum -L examples/acasxu/nets/onnx --format whyml examples/acasxu/property_1.why -t 10m
<span class="go">[caisar] Goal P1_1_1: Valid</span>
</pre></div>
</div>
<p>Note that the previous commands set the verification time limit to 10 minutes
(<em>cf.</em> <code class="docutils literal notranslate"><span class="pre">-t</span></code> option), and the additional location <code class="docutils literal notranslate"><span class="pre">examples/acasxu/nets/onnx</span></code>
(<em>cf.</em> <code class="docutils literal notranslate"><span class="pre">-L</span></code> option) for letting CAISAR correctly locate the neural network
file <code class="docutils literal notranslate"><span class="pre">ACASXU_1_1.onnx</span></code> that is used by the <code class="docutils literal notranslate"><span class="pre">ACASXU_P1</span></code> theory in
<code class="docutils literal notranslate"><span class="pre">property_1.why</span></code>.</p>
<p>Under the hood, CAISAR first translates each goal into a compatible form for the
targeted provers, then calls the provers on them, and finally interprets and
post-processes the prover results for displaying them in a coherent form to the
user.</p>
<p>Marabou is not able to prove the property valid in the specified time limit,
while nnenum does. In general, the result of a CAISAR verification is typically
either <code class="docutils literal notranslate"><span class="pre">Valid</span></code>, <code class="docutils literal notranslate"><span class="pre">Invalid</span></code>, <code class="docutils literal notranslate"><span class="pre">Unknown</span></code> or <code class="docutils literal notranslate"><span class="pre">Timeout</span></code>. CAISAR may output
<code class="docutils literal notranslate"><span class="pre">Failure</span></code> whenever the verification process fails for whatever reason
(typically, a prover internal failure).</p>
</section>
<section id="using-more-advanced-whyml-constructs">
<h3><span class="section-number">4.1.1.4. </span>Using more advanced WhyML constructs<a class="headerlink" href="#using-more-advanced-whyml-constructs" title="Permalink to this headline">¶</a></h3>
<p>Let us model the ACAS-Xu property <span class="math notranslate nohighlight">\(\phi_3\)</span>, and verify it for the neural
networks <span class="math notranslate nohighlight">\(N_{1,1}\)</span> and <span class="math notranslate nohighlight">\(N_{2,7}\)</span> <a class="reference internal" href="#katz2017" id="id4"><span>[Katz2017]</span></a>.</p>
<p>From the modelling standpoint, the main evident difference concerns the desired
output property, meaining that <em>COC</em> should not be the minimal value. A
straightforward way to express this property is that the corresponding
floating-point constant <span class="math notranslate nohighlight">\(y_0\)</span> is greater than or equal to at least one of
the other five outputs. This can be formalized in first-order logic as a
disjunction of clauses, that can be directly encoded into WhyML as follows:</p>
<div class="highlight-whyml notranslate"><div class="highlight"><pre><span></span><span class="n">y0</span> <span class="p">.</span><span class="o">&gt;=</span> <span class="n">y1</span> <span class="o">\/</span> <span class="n">y0</span> <span class="p">.</span><span class="o">&gt;=</span> <span class="n">y2</span> <span class="o">\/</span> <span class="n">y0</span> <span class="p">.</span><span class="o">&gt;=</span> <span class="n">y3</span> <span class="o">\/</span> <span class="n">y0</span> <span class="p">.</span><span class="o">&gt;=</span> <span class="n">y4</span>
</pre></div>
</div>
<p>The delicate point is how to model the same property for two different neural
networks. Of course, we could define a theory with two identical but distinct
verification goals or two entirely distinct theories in a same WhyML file.
However, these two solutions are not advisable in terms of clarity and
maintainability.</p>
<p>Reassuringly enough, WhyML provides all necessary features to come up with a
better solution. First, we can use the <code class="docutils literal notranslate"><span class="pre">read_neural_network</span></code>
extension as much as needed to represent distinct neural networks.
Second, WhyML allows for the hypotheses on
the floating-point constants modelling the neural network inputs to be exported
from the verification goal into the theory general context as axioms.</p>
<p>In the end, the WhyML file looks like this:</p>
<div class="highlight-whyml notranslate"><div class="highlight"><pre><span></span><span class="k">theory</span> <span class="n">ACASXU_P3</span>
  <span class="k">use</span> <span class="n">ieee_float</span><span class="p">.</span><span class="n">Float64</span>
  <span class="k">use</span> <span class="n">int</span><span class="p">.</span><span class="n">Int</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">Vector</span>
  <span class="k">use</span> <span class="n">interpretation</span><span class="p">.</span><span class="n">NeuralNetwork</span>

  <span class="k">constant</span> <span class="n">nn_1_1</span><span class="p">:</span> <span class="n">nn</span> <span class="o">=</span> <span class="n">read_neural_network</span> <span class="s2">&quot;nets/onnx/ACASXU_1_1.onnx&quot;</span> <span class="n">ONNX</span>
  <span class="k">constant</span> <span class="n">nn_2_7</span><span class="p">:</span> <span class="n">nn</span> <span class="o">=</span> <span class="n">read_neural_network</span> <span class="s2">&quot;nets/onnx/ACASXU_2_7.onnx&quot;</span> <span class="n">ONNX</span>

  <span class="k">predicate</span> <span class="n">valid_input</span> <span class="p">(</span><span class="n">i</span><span class="p">:</span> <span class="n">vector</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span>
    <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">3035311560999999769272506000561406835913658142089843750000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">2985528118999999924731980627257144078612327575683593750000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">0095492965999999998572000947660853853449225425720214843750000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">0095492965999999998572000947660853853449225425720214843750000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">4933803236000000036476365039561642333865165710449218750000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">2999999999999999888977697537484345957636833190917968750000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>
    <span class="o">/\</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">2999999999999999888977697537484345957636833190917968750000000000</span><span class="p">:</span><span class="n">t</span><span class="p">)</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">i</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">:</span><span class="n">t</span><span class="p">)</span>

  <span class="k">predicate</span> <span class="n">is_min</span> <span class="p">(</span><span class="n">o</span><span class="p">:</span> <span class="n">vector</span> <span class="n">t</span><span class="p">)</span> <span class="p">(</span><span class="n">i</span><span class="p">:</span> <span class="n">int</span><span class="p">)</span> <span class="o">=</span>
    <span class="k">forall</span> <span class="n">j</span><span class="p">:</span> <span class="n">int</span><span class="p">.</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">5</span> <span class="o">-&gt;</span> <span class="n">i</span> <span class="o">&lt;&gt;</span> <span class="n">j</span> <span class="o">-&gt;</span> <span class="n">o</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">.</span><span class="o">&lt;=</span> <span class="n">o</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

  <span class="k">goal</span> <span class="n">P3_1_1</span><span class="p">:</span>
    <span class="k">forall</span> <span class="n">i</span><span class="p">:</span> <span class="n">vector</span> <span class="n">t</span><span class="p">.</span> <span class="n">has_length</span> <span class="n">i</span> <span class="mi">5</span> <span class="o">-&gt;</span> <span class="n">valid_input</span> <span class="n">i</span> <span class="o">-&gt;</span> <span class="k">not</span> <span class="p">(</span><span class="n">is_min</span> <span class="p">(</span><span class="n">nn_1_1</span><span class="err">@@</span><span class="n">i</span><span class="p">)</span> <span class="mi">0</span><span class="p">)</span>

  <span class="k">goal</span> <span class="n">P3_2_7</span><span class="p">:</span>
    <span class="k">forall</span> <span class="n">i</span><span class="p">:</span> <span class="n">vector</span> <span class="n">t</span><span class="p">.</span> <span class="n">has_length</span> <span class="n">i</span> <span class="mi">5</span> <span class="o">-&gt;</span> <span class="n">valid_input</span> <span class="n">i</span> <span class="o">-&gt;</span> <span class="k">not</span> <span class="p">(</span><span class="n">is_min</span> <span class="p">(</span><span class="n">nn_2_7</span><span class="err">@@</span><span class="n">i</span><span class="p">)</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
<p>Note how the two verification goals <code class="docutils literal notranslate"><span class="pre">P3_1_1</span></code> and <code class="docutils literal notranslate"><span class="pre">P3_2_7</span></code> are clearly almost
identical, but for the <code class="docutils literal notranslate"><span class="pre">nn</span></code> logic symbol used, identifying respectively
the <code class="docutils literal notranslate"><span class="pre">ACASXU_1_1.onnx</span></code> and <code class="docutils literal notranslate"><span class="pre">ACASXU_2_7.onnx</span></code> neural networks.</p>
<p>We can then verify the resulting verification problem as before:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>caisar verify --prover Marabou -L examples/acasxu/nets/onnx --format whyml examples/acasxu/property_3.why -t 10m
<span class="go">[caisar] Goal P3_1_1: Timeout</span>
<span class="go">[caisar] Goal P3_2_7: Valid</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>caisar verify --prover nnenum -L examples/acasxu/nets/onnx --format whyml examples/acasxu/property_3.why -t 10m
<span class="go">[caisar] Goal P3_1_1: Valid</span>
<span class="go">[caisar] Goal P3_2_7: Valid</span>
</pre></div>
</div>
<p>It is interesting to remark that, since Marabou does not support disjunctive
formulas, CAISAR first splits a disjunctive goal formula into conjunctive
sub-goals, then calls Marabou on each sub-goal, and finally post-processes the
sub-results to provide the final result corresponding to the original goal
formula.</p>
<dl class="citation">
<dt class="label" id="manfredi2016"><span class="brackets"><a class="fn-backref" href="#id1">Manfredi2016</a></span></dt>
<dd><p>G. Manfredi and Y. Jestin, <em>An introduction to ACAS Xu and the
challenges ahead</em>, 2016 IEEE/AIAA 35th Digital Avionics Systems Conference
(DASC), 2016, pp. 1-9, doi: 10.1109/DASC.2016.7778055</p>
</dd>
<dt class="label" id="katz2017"><span class="brackets">Katz2017</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id3">2</a>,<a href="#id4">3</a>)</span></dt>
<dd><p>Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J.
(2017). <em>Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks.</em>
CAV 2017, doi: 10.1007/978-3-319-63387-9_5</p>
</dd>
</dl>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">CAISAR</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="foreword.html">1. Foreword</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">2. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">3. Using CAISAR</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="examples.html">4. CAISAR by Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">4.1. Functional properties of ACAS-Xu</a></li>
<li class="toctree-l2"><a class="reference internal" href="mnist.html">4.2. (Local) Robustness of MNIST dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">5. Index</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="examples.html"><span class="section-number">4. </span>CAISAR by Examples</a><ul>
      <li>Previous: <a href="examples.html" title="previous chapter"><span class="section-number">4. </span>CAISAR by Examples</a></li>
      <li>Next: <a href="mnist.html" title="next chapter"><span class="section-number">4.2. </span>(Local) Robustness of MNIST dataset</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, The CAISAR Development Team.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.3.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="sources/acas_xu.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>